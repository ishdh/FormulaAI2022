{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c175f7",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df5e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os,errno\n",
    "import sys\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a7793186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>M_SESSION_UID</th>\n",
       "      <th>M_SESSION_TIME</th>\n",
       "      <th>M_FRAME_IDENTIFIER</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>M_ZONE_START</th>\n",
       "      <th>M_ZONE_FLAG</th>\n",
       "      <th>M_TRACK_TEMPERATURE</th>\n",
       "      <th>M_TRACK_LENGTH</th>\n",
       "      <th>M_FORECAST_ACCURACY</th>\n",
       "      <th>...</th>\n",
       "      <th>M_WEATHER_FORECAST_SAMPLES_M_WEATHER</th>\n",
       "      <th>M_WEATHER_FORECAST_SAMPLES_M_TRACK_TEMPERATURE</th>\n",
       "      <th>M_TRACK_TEMPERATURE_CHANGE</th>\n",
       "      <th>M_WEATHER_FORECAST_SAMPLES_M_AIR_TEMPERATURE</th>\n",
       "      <th>M_AIR_TEMPERATURE_CHANGE</th>\n",
       "      <th>M_RAIN_PERCENTAGE</th>\n",
       "      <th>M_WEATHER</th>\n",
       "      <th>M_AI_DIFFICULTY</th>\n",
       "      <th>M_TOTAL_LAPS</th>\n",
       "      <th>Num_Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.300210e+19</td>\n",
       "      <td>2803.836</td>\n",
       "      <td>82458</td>\n",
       "      <td>1.642362e+09</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>4650</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.300210e+19</td>\n",
       "      <td>2803.836</td>\n",
       "      <td>82458</td>\n",
       "      <td>1.642362e+09</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>4650</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.300210e+19</td>\n",
       "      <td>2803.836</td>\n",
       "      <td>82458</td>\n",
       "      <td>1.642362e+09</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>4650</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.300210e+19</td>\n",
       "      <td>2803.836</td>\n",
       "      <td>82458</td>\n",
       "      <td>1.642362e+09</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>4650</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.300210e+19</td>\n",
       "      <td>2803.836</td>\n",
       "      <td>82458</td>\n",
       "      <td>1.642362e+09</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>4650</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  M_SESSION_UID  M_SESSION_TIME  M_FRAME_IDENTIFIER  \\\n",
       "0           0   1.300210e+19        2803.836               82458   \n",
       "1           1   1.300210e+19        2803.836               82458   \n",
       "2           2   1.300210e+19        2803.836               82458   \n",
       "3           3   1.300210e+19        2803.836               82458   \n",
       "4           4   1.300210e+19        2803.836               82458   \n",
       "\n",
       "      TIMESTAMP  M_ZONE_START  M_ZONE_FLAG  M_TRACK_TEMPERATURE  \\\n",
       "0  1.642362e+09         0.088          0.0                   33   \n",
       "1  1.642362e+09         0.167          0.0                   33   \n",
       "2  1.642362e+09         0.238          0.0                   33   \n",
       "3  1.642362e+09         0.298          0.0                   33   \n",
       "4  1.642362e+09         0.353          0.0                   33   \n",
       "\n",
       "   M_TRACK_LENGTH  M_FORECAST_ACCURACY  ...  \\\n",
       "0            4650                    0  ...   \n",
       "1            4650                    0  ...   \n",
       "2            4650                    0  ...   \n",
       "3            4650                    0  ...   \n",
       "4            4650                    0  ...   \n",
       "\n",
       "   M_WEATHER_FORECAST_SAMPLES_M_WEATHER  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "\n",
       "   M_WEATHER_FORECAST_SAMPLES_M_TRACK_TEMPERATURE  M_TRACK_TEMPERATURE_CHANGE  \\\n",
       "0                                             0.0                         0.0   \n",
       "1                                             0.0                         0.0   \n",
       "2                                             0.0                         0.0   \n",
       "3                                             0.0                         0.0   \n",
       "4                                             0.0                         0.0   \n",
       "\n",
       "   M_WEATHER_FORECAST_SAMPLES_M_AIR_TEMPERATURE  M_AIR_TEMPERATURE_CHANGE  \\\n",
       "0                                           0.0                       0.0   \n",
       "1                                           0.0                       0.0   \n",
       "2                                           0.0                       0.0   \n",
       "3                                           0.0                       0.0   \n",
       "4                                           0.0                       0.0   \n",
       "\n",
       "   M_RAIN_PERCENTAGE  M_WEATHER  M_AI_DIFFICULTY  M_TOTAL_LAPS  \\\n",
       "0                0.0          0                0         200.0   \n",
       "1                0.0          0                0         200.0   \n",
       "2                0.0          0                0         200.0   \n",
       "3                0.0          0                0         200.0   \n",
       "4                0.0          0                0         200.0   \n",
       "\n",
       "   Num_Predictions  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fe037a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3572282 entries, 0 to 3572281\n",
      "Data columns (total 30 columns):\n",
      " #   Column                                          Dtype  \n",
      "---  ------                                          -----  \n",
      " 0   Unnamed: 0                                      int64  \n",
      " 1   M_SESSION_UID                                   float64\n",
      " 2   M_SESSION_TIME                                  float64\n",
      " 3   M_FRAME_IDENTIFIER                              int64  \n",
      " 4   TIMESTAMP                                       float64\n",
      " 5   M_ZONE_START                                    float64\n",
      " 6   M_ZONE_FLAG                                     float64\n",
      " 7   M_TRACK_TEMPERATURE                             int64  \n",
      " 8   M_TRACK_LENGTH                                  int64  \n",
      " 9   M_FORECAST_ACCURACY                             int64  \n",
      " 10  M_AIR_TEMPERATURE                               int64  \n",
      " 11  M_NUM_WEATHER_FORECAST_SAMPLES                  int64  \n",
      " 12  M_TRACK_ID                                      int64  \n",
      " 13  M_SEASON_LINK_IDENTIFIER                        int64  \n",
      " 14  M_SESSION_TYPE                                  int64  \n",
      " 15  M_WEEKEND_LINK_IDENTIFIER                       int64  \n",
      " 16  M_SESSION_TIME_LEFT                             int64  \n",
      " 17  M_SESSION_DURATION                              int64  \n",
      " 18  M_WEATHER_FORECAST_SAMPLES_M_SESSION_TYPE       float64\n",
      " 19  M_TIME_OFFSET                                   float64\n",
      " 20  M_WEATHER_FORECAST_SAMPLES_M_WEATHER            float64\n",
      " 21  M_WEATHER_FORECAST_SAMPLES_M_TRACK_TEMPERATURE  float64\n",
      " 22  M_TRACK_TEMPERATURE_CHANGE                      float64\n",
      " 23  M_WEATHER_FORECAST_SAMPLES_M_AIR_TEMPERATURE    float64\n",
      " 24  M_AIR_TEMPERATURE_CHANGE                        float64\n",
      " 25  M_RAIN_PERCENTAGE                               float64\n",
      " 26  M_WEATHER                                       int64  \n",
      " 27  M_AI_DIFFICULTY                                 int64  \n",
      " 28  M_TOTAL_LAPS                                    float64\n",
      " 29  Num_Predictions                                 int64  \n",
      "dtypes: float64(14), int64(16)\n",
      "memory usage: 817.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4fe874af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split input and output for the model\n",
    "Y=df['M_WEATHER']\n",
    "Numpred=df['Num_Predictions']\n",
    "rainpercentage=df['M_RAIN_PERCENTAGE']\n",
    "X=df.drop(['M_WEATHER', 'M_RAIN_PERCENTAGE', 'Num_Predictions', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b2203048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a96ebde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2679211, 27)\n",
      "(2679211,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "46b7ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numpy arrays into tensors\n",
    "x_torch_train = torch.from_numpy(X_train.to_numpy()).type(torch.Tensor)\n",
    "x_torch_test = torch.from_numpy(X_test.to_numpy()).type(torch.Tensor)\n",
    "y_torch_train = torch.from_numpy(y_train.to_numpy()).type(torch.Tensor)\n",
    "y_torch_test = torch.from_numpy(y_test.to_numpy()).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "031c3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lstm_encoder(nn.Module):\n",
    "\t''' Encodes time-series sequence '''\n",
    "\n",
    "\tdef __init__(self, input_size, hidden_size,num_layers):\n",
    "\t\t'''\n",
    "        : param input_size:     the number of features in the input X\n",
    "        : param hidden_size:    the number of features in the hidden state h\n",
    "        : param num_layers:     number of recurrent layers (i.e., 2 means there are\n",
    "        :                       2 stacked LSTMs)\n",
    "        '''\n",
    "\n",
    "\t\tsuper(lstm_encoder,self).__init__()\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.num_layers = num_layers\n",
    "\n",
    "\t\tself.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional = False)\n",
    "\n",
    "\tdef forward(self,x_input):\n",
    "\t\t#x_input = input of shape(seq_len, batch_size, input_size)\n",
    "\t\t'''\n",
    "        : param x_input:               input of shape (seq_len, # in batch, input_size)\n",
    "        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence;\n",
    "        :                              hidden gives the hidden state and cell state for the last\n",
    "        :                              element in the sequence \n",
    "        '''\n",
    "\n",
    "\t\tlstm_out, self.hidden = self.lstm(x_input.view(x_input.shape[0],x_input.shape[1],sefl.input_size))\n",
    "\n",
    "\t\treturn lstm_out, self.hidden\n",
    "\n",
    "\tdef init_hidden(self, batch_size):\n",
    "\t\t'''\n",
    "        initialize hidden state\n",
    "        : param batch_size:    x_input.shape[1]\n",
    "        : return:              zeroed hidden state and cell state \n",
    "        '''\n",
    "\n",
    "\t\treturn(torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "\t\t\ttorch.zeros(self.num_layers,batch_size,self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4794c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lstm_decoder(nn.Module):\t\n",
    "\t''' Decodes hidden state output by encoder '''\n",
    "\n",
    "\tdef __init__(self, input_size, hidden_size, num_layers):\n",
    "\t\t'''\n",
    "        : param input_size:     the number of features in the input X\n",
    "        : param hidden_size:    the number of features in the hidden state h\n",
    "        : param num_layers:     number of recurrent layers (i.e., 2 means there are\n",
    "        :                       2 stacked LSTMs)\n",
    "        '''\n",
    "\n",
    "\t\tsuper(lstm_decoder, self).__init__()\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.num_layers = num_layers\n",
    "\n",
    "\t\tself.lstm = nn.LSTM(input_size = input_size, hidden_size= hidden_size, num_layers=num_layers, bidirectional = False)\n",
    "\n",
    "\t\tself.linear = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "\tdef forward(self, x_input, encoder_hidden_states):\n",
    "\t\t'''        \n",
    "        : param x_input:                    should be 2D (batch_size, input_size)\n",
    "        : param encoder_hidden_states:      hidden states\n",
    "        : return output, hidden:            output gives all the hidden states in the sequence;\n",
    "        :                                   hidden gives the hidden state and cell state for the last\n",
    "        :                                   element in the sequence \n",
    " \n",
    "        '''\n",
    "\n",
    "\t\tlstm_out, self.hidden = self.lstm(x_input.unsqueeze(0), encoder_hidden_states)\n",
    "\t\toutput = self.linear(lstm_out.squeeze(0))\n",
    "\n",
    "\t\treturn output, self.hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "44aa6553",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    def train_model(self, input_tensor, target_tensor, n_epochs, target_len, batch_size, training_prediction = 'recursive', teacher_forcing_ratio = 0.5, learning_rate = 0.01, dynamic_tf = False):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class lstm_seq2seq(nn.Module):\n",
    "\t''' train LSTM encoder-decoder and make predictions '''\n",
    "\n",
    "\tdef __init__(self, input_size, hidden_size):\n",
    "\t\t'''\n",
    "        : param input_size:     the number of expected features in the input X\n",
    "        : param hidden_size:    the number of features in the hidden state h\n",
    "        '''\n",
    "\n",
    "\n",
    "\t\tsuper(lstm_seq2seq,self).__init__()\n",
    "\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\n",
    "\t\tself.encoder = lstm_encoder(input_size = input_size, hidden_size = hidden_size)\n",
    "\t\tself.decoder = lstm_decoder(input_size = input_size, hidden_size = hidden_size)\n",
    "\n",
    "   \n",
    "    def train_model(self, input_tensor, target_tensor, n_epochs, target_len, batch_size, training_prediction = 'recursive',\n",
    "                    teacher_forcing_ratio = 0.5, learning_rate = 0.01, dynamic_tf = False):\n",
    "    \t'''\n",
    "        train lstm encoder-decoder\n",
    "        \n",
    "        : param input_tensor:              input data with shape (seq_len, # in batch, number features); PyTorch tensor    \n",
    "        : param target_tensor:             target data with shape (seq_len, # in batch, number features); PyTorch tensor\n",
    "        : param n_epochs:                  number of epochs \n",
    "        : param target_len:                number of values to predict \n",
    "        : param batch_size:                number of samples per gradient update\n",
    "        : param training_prediction:       type of prediction to make during training ('recursive', 'teacher_forcing', or\n",
    "        :                                  'mixed_teacher_forcing'); default is 'recursive'\n",
    "        : param teacher_forcing_ratio:     float [0, 1) indicating how much teacher forcing to use when\n",
    "        :                                  training_prediction = 'teacher_forcing.' For each batch in training, we generate a random\n",
    "        :                                  number. If the random number is less than teacher_forcing_ratio, we use teacher forcing.\n",
    "        :                                  Otherwise, we predict recursively. If teacher_forcing_ratio = 1, we train only using\n",
    "        :                                  teacher forcing.\n",
    "        : param learning_rate:             float >= 0; learning rate\n",
    "        : param dynamic_tf:                use dynamic teacher forcing (True/False); dynamic teacher forcing\n",
    "        :                                  reduces the amount of teacher forcing for each epoch\n",
    "        : return losses:                   array of loss function for each epoch\n",
    "        '''\n",
    "\n",
    "    \tlosses = np.full(n_epochs, np.nan)\n",
    "\n",
    "    \toptimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "    \tcriterion = nn.MSELoss()\n",
    "\n",
    "    \t#calculate number of batch iterations\n",
    "    \tn_batches = int(input_tensor.shape[1]/batch_size)\n",
    "\n",
    "    \twith trange(n_epochs) as tr:\n",
    "    \t\tfor it in tr:\n",
    "\n",
    "    \t\t\tbatch_loss = 0\n",
    "    \t\t\tbatch_loss_tf = 0\n",
    "    \t\t\tbatch_loss_no_tf = 0\n",
    "    \t\t\tnum_tf = 0\n",
    "    \t\t\tnum_no_tf = 0\n",
    "\n",
    "    \t\t\tfor b in range(n_batches):\n",
    "    \t\t\t\t#select data\n",
    "    \t\t\t\tinput_batch = input_tensor[:,b:b+batch_size,:]\n",
    "    \t\t\t\ttarget_batch = target_tensor[:,b:b+batch_size,:]\n",
    "\n",
    "    \t\t\t\t#output tensor\n",
    "    \t\t\t\toutputs = torch.zeros(target_len, batch_size, input_batch.shape[2])\n",
    "\n",
    "    \t\t\t\t#initiate hidden state\n",
    "    \t\t\t\tencoder_hidden = self.encoder.init_hidden(batch_size)\n",
    "\n",
    "    \t\t\t\t#zero the gradient\n",
    "    \t\t\t\toptimizer.zero_grad()\n",
    "\n",
    "    \t\t\t\t#encoder_outputs\n",
    "    \t\t\t\tencoder_output, encoder_hidden = self.encoder(input_batch)\n",
    "\n",
    "    \t\t\t\t#decoder outputs\n",
    "    \t\t\t\tdecoder_input = input_batch[-1,:,:]#shape:(batch_size,input_size)\n",
    "    \t\t\t\tdecoder_hidden = encoder_hidden\n",
    "\n",
    "    \t\t\t\tif training_prediction == 'recursive':\n",
    "\n",
    "    \t\t\t\t\tfor t in range(target_len):\n",
    "    \t\t\t\t\t\tdecoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "    \t\t\t\t\t\toutputs[t] = decoder_output\n",
    "    \t\t\t\t\t\tdecoder_input = decoder_output\n",
    "\n",
    "    \t\t\t\t\n",
    "    \t\t\t\tif training_prediction == 'teacher_forcing':\n",
    "    \t\t\t\t\tfor t in range(target_len):\n",
    "    \t\t\t\t\t\tdecoder_output, decoder_hidden = self.decoder(decoder_input,decoder_hidden)\n",
    "    \t\t\t\t\t\toutputs[t] = decoder_output\n",
    "\n",
    "    \t\t\t\t\t\tif random.random()<teacher_forcing_ratio:#teacher forcing\n",
    "    \t\t\t\t\t\t\tdecoder_input = target_batch[t,:,:]\n",
    "\n",
    "    \t\t\t\t\t\telse:#recursive\n",
    "    \t\t\t\t\t\t\tdecoder_input = decoder_output\n",
    "\n",
    "    \t\t\t\tloss = criterion(outputs, target_batch)\n",
    "    \t\t\t\tbatch_loss += loss.item()\n",
    "\n",
    "    \t\t\t\t#backpropogation\n",
    "    \t\t\t\tloss.backward()\n",
    "    \t\t\t\toptimizer.step()\n",
    "\n",
    "    \t\t\t#epoch loss\n",
    "    \t\t\tbatch_loss /= n_batches\n",
    "    \t\t\tlosses[it] = batch_loss\n",
    "\n",
    "    \t\t\t#dynamic teacher forcing\n",
    "    \t\t\tif dynamic_tf and teacher_forcing_ratio>0:\n",
    "    \t\t\t\tteacher_forcing_ratio = teacher_forcing_ratio-0.02\n",
    "\n",
    "    \t\t\t#progress bar\n",
    "    \t\t\ttr.set_postfix(loss =\"{0:3f}\".format(batch_loss))\n",
    "\n",
    "    \treturn losses\n",
    "\n",
    "    def predict(self, input_tensor, target_len):\n",
    "    \t'''\n",
    "        : param input_tensor:      input data (seq_len, input_size); PyTorch tensor \n",
    "        : param target_len:        number of target values to predict \n",
    "        : return np_outputs:       np.array containing predicted values; prediction done recursively \n",
    "        '''\n",
    "\n",
    "    \t#encode input tensor\n",
    "    \tinput_tensor = input_tensor.unsqueeze(1) #add in batch size of 1\n",
    "    \tencoder_output, encoder_hidden = self.encoder(input_tensor)\n",
    "\n",
    "    \t#initialize tensor for prediction\n",
    "    \toutputs = torch.zeros(target_len, input_tensor.shape[2])\n",
    "\n",
    "    \t#decode input_tensor\n",
    "    \tdecoder_input = input_tensor[-1:,:]\n",
    "    \tdecoder_hidden = encoder_hidden\n",
    "\n",
    "    \tfor t in range(target_len):\n",
    "    \t\tdecoder_output, decoder_hidden = self.decoder(decoder_input,decoder_hidden)\n",
    "    \t\toutputs[t] = decoder_output.squeeze(0)\n",
    "    \t\tdecoder_input = decoder_output\n",
    "\n",
    "    \tnp_outputs = outputs.detach().numpy()\n",
    "\n",
    "    \treturn np_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e27b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = lstm_encoder_decoder.lstm_seq2seq(input_size = X_train.shape[2], hidden_size = 15)\n",
    "model.to(device)\n",
    "x_torch_train.to(device)\n",
    "_train.to(device)\n",
    "X_test.to(device)\n",
    "Y_test.to(device)\n",
    "loss = model.train_model(X_train, Y_train, n_epochs = , target_len = , batch_size = , training_prediction = 'teacher_forcing', teacher_forcing_ratio = 0.6, learning_rate = 0.01, dynamic_tf = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
